\relax 
\citation{Tran16unsupervised}
\citation{Ghader2017what}
\citation{Rikters2017confidence}
\citation{Conneau2017Word}
\citation{Liang2006Alignment}
\citation{Yang13word}
\citation{Tamura14recurrent}
\citation{Och2003Systematic}
\citation{Och2003Systematic}
\citation{Tran16unsupervised}
\citation{Yang13word}
\citation{Tamura14recurrent}
\citation{Tran16unsupervised}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Paper report}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Unsupervised Neural HMMs \citep  {Tran16unsupervised}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Main idea}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}What is their concentration ?}{3}}
\newlabel{Tran16unsupervised Gradient Joint Probability}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}What is the role of HMM ?}{4}}
\newlabel{Tran16unsupervised Probability HMM}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Where is neural network ?}{4}}
\citation{Ghader2017what}
\@writefile{toc}{\contentsline {section}{\numberline {2}What does Attention in NMT pay Attention to ? \citep  {Ghader2017what} }{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Main idea}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}How to compare ?}{5}}
\citation{Rikters2017confidence}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Analysis}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Confidence through Attention \citep  {Rikters2017confidence}}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Main idea}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}How to calculate Confidence metric ?}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Analysis}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Comparison with human evaluation}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Exp: Filtering Back-translated Data}{7}}
\citation{Conneau2017Word}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Exp: Hybrid Decisions}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Word Translation without Parallel data \citep  {Conneau2017Word}}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Main idea}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}How does it works ?}{8}}
\citation{Liang2006Alignment}
\citation{Yang13word}
\@writefile{toc}{\contentsline {section}{\numberline {5}Alignment by Agreement \citep  {Liang2006Alignment}}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Main idea}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Word Alignment Modeling with Context Dependent Deep Neural Network \citep  {Yang13word}}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Main idea}{9}}
\citation{Vogel1996HMM}
\citation{Vogel1996HMM}
\citation{Vogel1996HMM}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}How does DNN work in word alignment ?}{10}}
\newlabel{Yang13word NN Alignment Score}{{17}{10}}
\newlabel{Yang13word Lexical Translation Score}{{18}{10}}
\citation{Tamura14recurrent}
\citation{Yang13word}
\citation{Yang13word}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Loss in supervised learning}{11}}
\newlabel{Yang13word Alignment Loss}{{21}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Analysis}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.1}Two loss functions during training}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.2}Result}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.3}Notes}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Recurrent Neural Networks for Word Alignment Model \citep  {Tamura14recurrent}}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Main idea}{11}}
\citation{Yang13word}
\citation{Liang2006Alignment}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}How does RNNs work in calculating alignment score ?}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Loss in unsupervised learning}{12}}
\newlabel{Tamura14recurrent Loss Unsupervised Learning}{{25}{12}}
\citation{Yang13word}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Agreement constraints}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Analysis}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.1}Result}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Hierarchical Multiscale Recurrent Neural Networks}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Main idea}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Update mechanism}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Analysis}{15}}
\citation{Och2003Systematic}
\citation{Och2003Systematic}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Report}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Overview about statistical alignment }{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Word-based alignment ? \cite  {Och2003Systematic}}{16}}
\newlabel{Overview about Statistical Alignment p(f,e)}{{32}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Hidden Markov Alignment Model \cite  {Och2003Systematic}}{16}}
\citation{Vogel1996HMM}
\newlabel{Och2003Systematic Alignment Model Equation}{{35}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.1}Assumption about HMM alignment probability $p(a_j | a_{j-1}, I)$ or $p(i | i', I)$}{17}}
\citation{Tran16unsupervised}
\citation{Tran16unsupervised}
\citation{Tran16unsupervised}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2}Extension: Empty word in target sentence}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.3}Extension: Refinement of alignment}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Word alignment model in Neural Network}{18}}
\newlabel{Word Alignment Model Neural Network p(f,e)}{{40}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Probability approach}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.1.1}\cite  {Tran16unsupervised}}{18}}
\citation{Yang13word}
\citation{Tamura14recurrent}
\@writefile{toc}{\contentsline {paragraph}{How to apply NN ?}{19}}
\@writefile{toc}{\contentsline {paragraph}{What is the problem of transition matrix in programming ?}{19}}
\citation{Ghader2017what}
\citation{Rikters2017confidence}
\citation{Rikters2017confidence}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Non-probability - Score approach}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.1}\cite  {Yang13word}, \cite  {Tamura14recurrent}}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Symmetrical alignment}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {12}Techniques in Alignment}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1}Agreement between models}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {13}Evaluation of a translation/alignment}{20}}
\bibstyle{plain}
\bibdata{Khoa_Alignment_Paper}
\bibcite{Conneau2017Word}{{1}{}{{}}{{}}}
\bibcite{Ghader2017what}{{2}{}{{}}{{}}}
\bibcite{Liang2006Alignment}{{3}{}{{}}{{}}}
\bibcite{Och2003Systematic}{{4}{}{{}}{{}}}
\bibcite{Rikters2017confidence}{{5}{}{{}}{{}}}
\bibcite{Tamura14recurrent}{{6}{}{{}}{{}}}
\bibcite{Tran16unsupervised}{{7}{}{{}}{{}}}
\bibcite{Vogel1996HMM}{{8}{}{{}}{{}}}
\bibcite{Yang13word}{{9}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
